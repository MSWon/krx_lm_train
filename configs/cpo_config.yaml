datasets:
  preference:
    - name: "TwoSubPlace/finance_dpo_pairs"
      ratio: 1
    - name: "TwoSubPlace/finance_dpo_pairs2"
      ratio: 1

model:
  name: "unsloth/Qwen2-0.5B-Instruct-bnb-4bit"
  max_seq_length: 1024
  dtype: null
  load_in_4bit: true

lora:
  r: 64
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  lora_alpha: 16
  lora_dropout: 0
  bias: "none"
  use_gradient_checkpointing: "unsloth"
  random_state: 42
  use_rslora: true
  loftq_config: null

training:
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 8
  warmup_ratio: 0.05
  num_train_epochs: 2
  learning_rate: 0.0002
  logging_steps: 10
  optim: "adamw_8bit"
  weight_decay: 0.01
  lr_scheduler_type: "linear"
  seed: 42
  output_dir: "experiments-001"
  save_steps: 200
  eval_steps: 200
  evaluation_strategy: "steps"
  report_to: "none"
